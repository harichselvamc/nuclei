{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8089,"databundleVersionId":44321,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nimport random\nfrom tqdm import tqdm\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:12:11.588023Z","iopub.execute_input":"2024-08-24T08:12:11.588357Z","iopub.status.idle":"2024-08-24T08:12:32.876851Z","shell.execute_reply.started":"2024-08-24T08:12:11.58833Z","shell.execute_reply":"2024-08-24T08:12:32.876092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nTRAIN_ZIP = '/kaggle/input/data-science-bowl-2018/stage1_train.zip'\nTEST_ZIP = '/kaggle/input/data-science-bowl-2018/stage1_test.zip'\n# Directory where to extract\nTRAIN_PATH = '/kaggle/working/stage1_train/'\nTEST_PATH = '/kaggle/working/stage1_test/'\n\n# Unzip the train data\nwith zipfile.ZipFile(TRAIN_ZIP, 'r') as zip_ref:\n    zip_ref.extractall(TRAIN_PATH)\n\n# Unzip the test data\nwith zipfile.ZipFile(TEST_ZIP, 'r') as zip_ref:\n    zip_ref.extractall(TEST_PATH)\n\nprint(\"Extraction complete!\")","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:12:32.878673Z","iopub.execute_input":"2024-08-24T08:12:32.879327Z","iopub.status.idle":"2024-08-24T08:12:38.477571Z","shell.execute_reply.started":"2024-08-24T08:12:32.879293Z","shell.execute_reply":"2024-08-24T08:12:38.476617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ids = next(os.walk(TRAIN_PATH))[1] #gives the folder names\ntest_ids = next(os.walk(TEST_PATH))[1]","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:12:38.478788Z","iopub.execute_input":"2024-08-24T08:12:38.479188Z","iopub.status.idle":"2024-08-24T08:12:38.485448Z","shell.execute_reply.started":"2024-08-24T08:12:38.479148Z","shell.execute_reply":"2024-08-24T08:12:38.484495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_WIDTH = 128\nIMG_HEIGHT = 128\nIMG_CHANNELS = 3","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:12:38.488017Z","iopub.execute_input":"2024-08-24T08:12:38.488383Z","iopub.status.idle":"2024-08-24T08:12:38.505585Z","shell.execute_reply.started":"2024-08-24T08:12:38.488349Z","shell.execute_reply":"2024-08-24T08:12:38.504879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:12:38.518511Z","iopub.execute_input":"2024-08-24T08:12:38.518845Z","iopub.status.idle":"2024-08-24T08:12:38.531169Z","shell.execute_reply.started":"2024-08-24T08:12:38.518813Z","shell.execute_reply":"2024-08-24T08:12:38.530479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, Y_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:12:38.5322Z","iopub.execute_input":"2024-08-24T08:12:38.532509Z","iopub.status.idle":"2024-08-24T08:12:38.547109Z","shell.execute_reply.started":"2024-08-24T08:12:38.532479Z","shell.execute_reply":"2024-08-24T08:12:38.546337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 42\nnp.random.seed = seed","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:12:38.581926Z","iopub.execute_input":"2024-08-24T08:12:38.582229Z","iopub.status.idle":"2024-08-24T08:12:38.598095Z","shell.execute_reply.started":"2024-08-24T08:12:38.582205Z","shell.execute_reply":"2024-08-24T08:12:38.597225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   \n    path = TRAIN_PATH + id_\n    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]  \n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    # After resizing, ensure the data is in uint8 format and the range [0, 255]\n    if img.dtype != np.uint8:\n        img = np.clip(img, 0, 255)  # Clip values\n        img = img.astype(np.uint8)  # Convert to uint8\n    X_train[n] = img  #Fill empty X_train with values from img\n    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n    for mask_file in next(os.walk(path + '/masks/'))[2]:\n        mask_ = imread(path + '/masks/' + mask_file)\n        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n                                      preserve_range=True), axis=-1)\n        mask_ = mask_.astype(np.uint8)\n        \n        mask = np.maximum(mask, mask_)  \n    # Convert the mask to boolean\n    mask = (mask > 0).astype(bool)    \n    Y_train[n] = mask   ","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:12:38.599408Z","iopub.execute_input":"2024-08-24T08:12:38.599681Z","iopub.status.idle":"2024-08-24T08:16:44.574589Z","shell.execute_reply.started":"2024-08-24T08:12:38.599657Z","shell.execute_reply":"2024-08-24T08:16:44.573708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[0].shape, Y_train[0].shape","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:16:44.57574Z","iopub.execute_input":"2024-08-24T08:16:44.576034Z","iopub.status.idle":"2024-08-24T08:16:44.582468Z","shell.execute_reply.started":"2024-08-24T08:16:44.576009Z","shell.execute_reply":"2024-08-24T08:16:44.581487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imshow(X_train[0])\nplt.show()\nimshow(Y_train[0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:16:44.583761Z","iopub.execute_input":"2024-08-24T08:16:44.584383Z","iopub.status.idle":"2024-08-24T08:16:45.41601Z","shell.execute_reply.started":"2024-08-24T08:16:44.584355Z","shell.execute_reply":"2024-08-24T08:16:45.414847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test images\nX_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nsizes_test = []\nprint('Resizing test images') \nfor n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n    path = TEST_PATH + id_\n    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n    sizes_test.append([img.shape[0], img.shape[1]])\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    # print(img.dtype)\n    if img.dtype != np.uint8:\n        img = np.clip(img, 0, 255)  # Clip values\n        img = img.astype(np.uint8)  # Convert to uint8\n    X_test[n] = img\n\nprint('Done!')","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:16:45.417532Z","iopub.execute_input":"2024-08-24T08:16:45.417927Z","iopub.status.idle":"2024-08-24T08:16:46.797719Z","shell.execute_reply.started":"2024-08-24T08:16:45.417893Z","shell.execute_reply":"2024-08-24T08:16:46.796784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sizes_test[1]\nimshow(X_test[1])\nX_test[1].max()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:16:46.798775Z","iopub.execute_input":"2024-08-24T08:16:46.799046Z","iopub.status.idle":"2024-08-24T08:16:47.144534Z","shell.execute_reply.started":"2024-08-24T08:16:46.79902Z","shell.execute_reply":"2024-08-24T08:16:47.14362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_x = random.randint(0, len(train_ids))\nprint(image_x)\n\nimshow(X_train[image_x])\nplt.show()\nimshow(np.squeeze(Y_train[image_x]))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:16:47.145517Z","iopub.execute_input":"2024-08-24T08:16:47.145808Z","iopub.status.idle":"2024-08-24T08:16:47.745013Z","shell.execute_reply.started":"2024-08-24T08:16:47.145783Z","shell.execute_reply":"2024-08-24T08:16:47.74405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build the model\ninputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\ns = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n\n#Contraction path\nc1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\nc1 = tf.keras.layers.Dropout(0.1)(c1)\nc1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\np1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n\nc2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\nc2 = tf.keras.layers.Dropout(0.1)(c2)\nc2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\np2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n \nc3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\nc3 = tf.keras.layers.Dropout(0.2)(c3)\nc3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\np3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n \nc4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\nc4 = tf.keras.layers.Dropout(0.2)(c4)\nc4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\np4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n \nc5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\nc5 = tf.keras.layers.Dropout(0.3)(c5)\nc5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n\n#Expansive path \nu6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\nu6 = tf.keras.layers.concatenate([u6, c4])\nc6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\nc6 = tf.keras.layers.Dropout(0.2)(c6)\nc6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n \nu7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\nu7 = tf.keras.layers.concatenate([u7, c3])\nc7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\nc7 = tf.keras.layers.Dropout(0.2)(c7)\nc7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n \nu8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\nu8 = tf.keras.layers.concatenate([u8, c2])\nc8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\nc8 = tf.keras.layers.Dropout(0.1)(c8)\nc8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n \nu9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\nu9 = tf.keras.layers.concatenate([u9, c1], axis=3)\nc9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\nc9 = tf.keras.layers.Dropout(0.1)(c9)\nc9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n \noutputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n \nmodel = tf.keras.Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:42:31.696644Z","iopub.execute_input":"2024-08-24T08:42:31.697354Z","iopub.status.idle":"2024-08-24T08:42:31.983055Z","shell.execute_reply.started":"2024-08-24T08:42:31.697319Z","shell.execute_reply":"2024-08-24T08:42:31.982125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:42:32.179003Z","iopub.execute_input":"2024-08-24T08:42:32.17965Z","iopub.status.idle":"2024-08-24T08:42:32.183852Z","shell.execute_reply.started":"2024-08-24T08:42:32.179617Z","shell.execute_reply":"2024-08-24T08:42:32.182878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\n# Defining callbacks\ncheckpointer = tf.keras.callbacks.ModelCheckpoint('model_for_nuclei.keras', verbose=1, save_best_only=True)\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(filepath='model_for_nuclei.keras', verbose=1, save_best_only=True),\n    tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n#     tf.keras.callbacks.TensorBoard(log_dir='logs')\n    tensorboard_callback\n]","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:42:32.20906Z","iopub.execute_input":"2024-08-24T08:42:32.209566Z","iopub.status.idle":"2024-08-24T08:42:32.216017Z","shell.execute_reply.started":"2024-08-24T08:42:32.209539Z","shell.execute_reply":"2024-08-24T08:42:32.215343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clear any logs from previous runs\n!rm -rf /kaggle/working/logs","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:42:32.233665Z","iopub.execute_input":"2024-08-24T08:42:32.233925Z","iopub.status.idle":"2024-08-24T08:42:33.291259Z","shell.execute_reply.started":"2024-08-24T08:42:32.233902Z","shell.execute_reply":"2024-08-24T08:42:33.290255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=35, callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:42:33.293348Z","iopub.execute_input":"2024-08-24T08:42:33.293677Z","iopub.status.idle":"2024-08-24T08:43:32.013416Z","shell.execute_reply.started":"2024-08-24T08:42:33.293642Z","shell.execute_reply":"2024-08-24T08:43:32.01255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# type(results)\nresults.history","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:43:32.014829Z","iopub.execute_input":"2024-08-24T08:43:32.015156Z","iopub.status.idle":"2024-08-24T08:43:32.023509Z","shell.execute_reply.started":"2024-08-24T08:43:32.015126Z","shell.execute_reply":"2024-08-24T08:43:32.022438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = results.history\nplt.plot(history['loss'], label='Training Loss')\nplt.plot(history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:43:32.026322Z","iopub.execute_input":"2024-08-24T08:43:32.026973Z","iopub.status.idle":"2024-08-24T08:43:32.28265Z","shell.execute_reply.started":"2024-08-24T08:43:32.026941Z","shell.execute_reply":"2024-08-24T08:43:32.281648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = results.history\nplt.plot(history['accuracy'], label='Accuracy')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:43:32.283764Z","iopub.execute_input":"2024-08-24T08:43:32.284035Z","iopub.status.idle":"2024-08-24T08:43:32.521568Z","shell.execute_reply.started":"2024-08-24T08:43:32.28401Z","shell.execute_reply":"2024-08-24T08:43:32.520613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.input_shape","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:43:32.522669Z","iopub.execute_input":"2024-08-24T08:43:32.522933Z","iopub.status.idle":"2024-08-24T08:43:32.528781Z","shell.execute_reply.started":"2024-08-24T08:43:32.522908Z","shell.execute_reply":"2024-08-24T08:43:32.527854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display(display_list):\n    plt.figure(figsize=(15, 15))\n    title = ['Input image', 'True mask', 'Predicted mask']\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(display_list[i])\n        plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:43:32.530052Z","iopub.execute_input":"2024-08-24T08:43:32.530403Z","iopub.status.idle":"2024-08-24T08:43:32.539827Z","shell.execute_reply.started":"2024-08-24T08:43:32.53037Z","shell.execute_reply":"2024-08-24T08:43:32.53897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = random.randint(0, len(X_train))\ntrue_image = X_train[idx]\ntrue_mask = np.squeeze(Y_train[idx])\n# Add batch dimension and then predict\nprediction = model.predict(true_image[tf.newaxis, ...])[0]\n\npredicted_mask = (prediction > 0.5).astype(np.uint8)\nprint(predicted_mask.shape)\ndisplay([true_image, true_mask,predicted_mask])","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:54:15.679426Z","iopub.execute_input":"2024-08-24T08:54:15.679827Z","iopub.status.idle":"2024-08-24T08:54:16.126957Z","shell.execute_reply.started":"2024-08-24T08:54:15.679792Z","shell.execute_reply":"2024-08-24T08:54:16.126193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/unet.h5')","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:49:01.464779Z","iopub.execute_input":"2024-08-24T08:49:01.465502Z","iopub.status.idle":"2024-08-24T08:49:01.613162Z","shell.execute_reply.started":"2024-08-24T08:49:01.465463Z","shell.execute_reply":"2024-08-24T08:49:01.612326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_masks = model.predict(X_train)\n# For binary segmentation, we usually apply a threshold of 0.5\npredicted_masks = (predicted_masks > 0.5).astype(np.uint8)\n\n# Now `predicted_masks` is an array of shape (670, 128, 128, 1), similar to `y_train`\nprint(predicted_masks.shape) ","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:57:37.326208Z","iopub.execute_input":"2024-08-24T08:57:37.326626Z","iopub.status.idle":"2024-08-24T08:57:48.733411Z","shell.execute_reply.started":"2024-08-24T08:57:37.326589Z","shell.execute_reply":"2024-08-24T08:57:48.732482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create directories to save the true and predicted masks\ntrue_masks_folder = '/kaggle/working/true_masks'\npredicted_masks_folder = '/kaggle/working/predicted_masks'\nos.makedirs(true_masks_folder, exist_ok=True)\nos.makedirs(predicted_masks_folder, exist_ok=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:55:49.329658Z","iopub.execute_input":"2024-08-24T08:55:49.330031Z","iopub.status.idle":"2024-08-24T08:55:49.335339Z","shell.execute_reply.started":"2024-08-24T08:55:49.330004Z","shell.execute_reply":"2024-08-24T08:55:49.334458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nimport imageio\n# Assuming `true_masks` and `predicted_masks` are numpy arrays of shape (670, 128, 128, 1)\n# Iterate through all masks and save them as PNG images\nfor i in range(len(X_train)):  # Adjust the range based on the number of masks\n    # Get the i-th true and predicted mask\n    true_mask = np.squeeze(Y_train[i])  # Squeeze to remove the single channel dimension (128, 128)\n    predicted_mask = np.squeeze(predicted_masks[i])\n\n    # Create the paths to save the images\n    true_mask_save_path = os.path.join(true_masks_folder, f'true_mask_{i}.png')\n    predicted_mask_save_path = os.path.join(predicted_masks_folder, f'predicted_mask_{i}.png')\n\n    # Save the true and predicted masks as images\n    imageio.imwrite(true_mask_save_path, (true_mask * 255).astype(np.uint8))  # Scale if necessary\n    imageio.imwrite(predicted_mask_save_path, (predicted_mask * 255).astype(np.uint8))\n\nprint(\"True and Predicted masks saved in their respective folders.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:58:19.69489Z","iopub.execute_input":"2024-08-24T08:58:19.695607Z","iopub.status.idle":"2024-08-24T08:58:21.564524Z","shell.execute_reply.started":"2024-08-24T08:58:19.695568Z","shell.execute_reply":"2024-08-24T08:58:21.563505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now create zip archives for both directories\nshutil.make_archive('/kaggle/working/true_masks_archive', 'zip', true_masks_folder)\nshutil.make_archive('/kaggle/working/predicted_masks_archive', 'zip', predicted_masks_folder)\n\nprint(\"Masks folders zipped successfully.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:58:35.214891Z","iopub.execute_input":"2024-08-24T08:58:35.21528Z","iopub.status.idle":"2024-08-24T08:58:35.448868Z","shell.execute_reply.started":"2024-08-24T08:58:35.215246Z","shell.execute_reply":"2024-08-24T08:58:35.447929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}